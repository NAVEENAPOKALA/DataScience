{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4756d7-eb3f-4b34-964a-1ce22d79e0e8",
   "metadata": {},
   "source": [
    "# Data Analysis Homework 1: Pandas and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d60f6f-3e88-48da-a5eb-130d44a0600c",
   "metadata": {},
   "source": [
    "## Q1) 1. Load transit_segments.csv and vessel_information.csv and print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "46b2c9f8-9623-4d72-bb1c-5851c063989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0c9bf6ba-924a-42a9-8b76-a0094d96da96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mmsi               name  transit  segment  seg_length  avg_sog  min_sog  \\\n",
      "0     1        Us Govt Ves        1        1         5.1     13.2      9.2   \n",
      "1     1  Dredge Capt Frank        1        1        13.5     18.6     10.4   \n",
      "2     1      Us Gov Vessel        1        1         4.3     16.2     10.3   \n",
      "3     1      Us Gov Vessel        2        1         9.2     15.4     14.5   \n",
      "4     1  Dredge Capt Frank        2        1         9.2     15.4     14.6   \n",
      "\n",
      "   max_sog  pdgt10        st_time       end_time  \n",
      "0     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
      "1     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
      "2     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
      "3     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
      "4     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n"
     ]
    }
   ],
   "source": [
    "transit_data = pd.read_csv(\"./data/AIS/transit_segments.csv\")\n",
    "print(transit_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2bd856f5-b9e8-4487-a181-52323b9d388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mmsi  num_names                                              names sov  \\\n",
      "0     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "1     9          3                         000000009/Raven/Shearwater   N   \n",
      "2    21          1                                      Us Gov Vessel   Y   \n",
      "3    74          2                                  Mcfaul/Sarah Bell   N   \n",
      "4   103          3           Ron G/Us Navy Warship 103/Us Warship 103   Y   \n",
      "\n",
      "      flag flag_type  num_loas                                    loa  \\\n",
      "0  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "1  Unknown   Unknown         2                              50.0/62.0   \n",
      "2  Unknown   Unknown         1                                  208.0   \n",
      "3  Unknown   Unknown         1                                  155.0   \n",
      "4  Unknown   Unknown         2                             26.0/155.0   \n",
      "\n",
      "   max_loa  num_types                             type  \n",
      "0    156.0          4  Dredging/MilOps/Reserved/Towing  \n",
      "1     62.0          2                     Pleasure/Tug  \n",
      "2    208.0          1                          Unknown  \n",
      "3    155.0          1                          Unknown  \n",
      "4    155.0          2                   Tanker/Unknown  \n"
     ]
    }
   ],
   "source": [
    "vessel_data = pd.read_csv(\"./data/AIS/vessel_information.csv\")\n",
    "print(vessel_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a63f6-f6b4-4751-9241-722bfafb729f",
   "metadata": {},
   "source": [
    "## Q1) 2. Keep only those rows with the type value occurring for at least 99 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d166c81d-7cb0-4abe-8c71-cc093c187da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Types :  206\n",
      "Total Number of Types Occuring for atleast 99 times :  10\n",
      "type\n",
      "Cargo        5622\n",
      "Tanker       2440\n",
      "Pleasure      601\n",
      "Tug           221\n",
      "Sailing       205\n",
      "Fishing       200\n",
      "Other         178\n",
      "Passenger     150\n",
      "Towing        117\n",
      "Unknown       106\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "type_counts = vessel_data['type'].value_counts()\n",
    "print(\"Total Number of Types : \",type_counts.count())\n",
    "type_counts = type_counts[type_counts >= 99]\n",
    "print(\"Total Number of Types Occuring for atleast 99 times : \",type_counts.count())\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c0c55714-0c9d-45e2-8715-dace11899599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Records before dropping :  10771\n",
      "Total Number of Records After dropping :  9840\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Records before dropping : \",vessel_data.shape[0])\n",
    "vessel_data = vessel_data[vessel_data['type'].isin(type_counts.index)]\n",
    "print(\"Total Number of Records After dropping : \",vessel_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd7190-811f-47ad-9d23-6033f4f896a7",
   "metadata": {},
   "source": [
    "## Q1) 3. Merge data/AIS/vessel_information.csv and data/AIS/transit_segments.csv on the \"mmsi\" column using outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8164ea82-e4de-4463-851a-77668b53b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mmsi', 'num_names', 'names', 'sov', 'flag', 'flag_type', 'num_loas',\n",
      "       'loa', 'max_loa', 'num_types', 'type', 'name', 'transit', 'segment',\n",
      "       'seg_length', 'avg_sog', 'min_sog', 'max_sog', 'pdgt10', 'st_time',\n",
      "       'end_time'],\n",
      "      dtype='object')\n",
      "Total Number of Records after outer join :  262526\n"
     ]
    }
   ],
   "source": [
    "merged_data_outer = pd.merge(vessel_data,transit_data,on=\"mmsi\",how=\"outer\")\n",
    "print(merged_data_outer.columns)\n",
    "print(\"Total Number of Records after outer join : \",merged_data_outer.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162645a2-a307-4275-aca3-b8b4dae4eb00",
   "metadata": {},
   "source": [
    "## Q1) 4. Derive the inner join results without directly calling inner join in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9f138-4c66-40db-acc5-81a36ce4f942",
   "metadata": {},
   "source": [
    "#### Analysis : Outer join retains all the records even if they are not present in the other dataset. Hence, the merged dataset will have 'NaN' to all the columns of a transit dataset whose records are not present in vessel dataset and vice versa. Inner join contains the records whose mmsi is present in both the dataset. Hence, the merged dataset doesnt have 'NaN'. We can use this and remove all the records whose columns has NaN. The result will be the inner join of the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4324296e-dbbe-40ce-ad58-09afccb51a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mmsi', 'num_names', 'names', 'sov', 'flag', 'flag_type', 'num_loas',\n",
      "       'loa', 'max_loa', 'num_types', 'type', 'name', 'transit', 'segment',\n",
      "       'seg_length', 'avg_sog', 'min_sog', 'max_sog', 'pdgt10', 'st_time',\n",
      "       'end_time'],\n",
      "      dtype='object')\n",
      "Total Number of Records in inner join result without using inner join function :  197814\n"
     ]
    }
   ],
   "source": [
    "merged_data_inner = merged_data[\n",
    "    merged_data['type'].notna() &   # column from vessel_information\n",
    "    merged_data['max_sog'].notna()  # column from transit_segments\n",
    "]\n",
    "print(merged_data_inner.columns)\n",
    "print(\"Total Number of Records in inner join result without using inner join function : \",merged_data_inner.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef60fe-0baf-4888-8263-15325cfa050b",
   "metadata": {},
   "source": [
    "## Q1) 5. Directly call the inner join provided by Pandas, check whether your results above are exactly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1058158-84f8-4b8e-a3e7-79ce2c7f7445",
   "metadata": {},
   "source": [
    "#### Analysis : The result is same for the approaches. Meaning that the row count matched for both the approaches. This suggests that we can remove the NaN rows from outer join and produce inner join output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d861f98c-574d-47bc-980b-221c8817aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mmsi', 'num_names', 'names', 'sov', 'flag', 'flag_type', 'num_loas',\n",
      "       'loa', 'max_loa', 'num_types', 'type', 'name', 'transit', 'segment',\n",
      "       'seg_length', 'avg_sog', 'min_sog', 'max_sog', 'pdgt10', 'st_time',\n",
      "       'end_time'],\n",
      "      dtype='object')\n",
      "Total Number of Records in inner join result using inner join function :  197814\n"
     ]
    }
   ],
   "source": [
    "inner_join_result = pd.merge(vessel_data,transit_data,on=\"mmsi\",how=\"inner\")\n",
    "print(inner_join_result.columns)\n",
    "print(\"Total Number of Records in inner join result using inner join function : \",inner_join_result.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412d8ff-18f2-474d-965c-3218b9613dd7",
   "metadata": {},
   "source": [
    "## Q1) 6. Save merged dataset as AIS_merge.csv and check the missing values. Replace missing values with column mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d149ce02-f174-449a-905e-467f1d85723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_outer.to_csv(\"./AIS_merge.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4d4767e8-befe-47b5-a163-7d02fb58e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mmsi', 'num_names', 'names', 'sov', 'flag', 'flag_type', 'num_loas',\n",
      "       'loa', 'max_loa', 'num_types', 'type', 'name', 'transit', 'segment',\n",
      "       'seg_length', 'avg_sog', 'min_sog', 'max_sog', 'pdgt10', 'st_time',\n",
      "       'end_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data = pd.read_csv(\"./AIS_merge.csv\")\n",
    "print(AIS_merge_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cc73c95c-6344-4320-8b8e-77b702b5cb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mmsi              0\n",
       "num_names     64712\n",
       "names         64712\n",
       "sov           64712\n",
       "flag          64712\n",
       "flag_type     64712\n",
       "num_loas      64712\n",
       "loa           64712\n",
       "max_loa       64712\n",
       "num_types     64712\n",
       "type          64712\n",
       "name              0\n",
       "transit           0\n",
       "segment           0\n",
       "seg_length        0\n",
       "avg_sog           0\n",
       "min_sog           0\n",
       "max_sog           0\n",
       "pdgt10            0\n",
       "st_time           0\n",
       "end_time          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIS_merge_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f3a08de4-1091-47aa-a2c1-18647e04a35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of the all columns\n",
      "mmsi                          367063030\n",
      "num_names                           1.0\n",
      "names               Emerald Princess Ii\n",
      "sov                                   N\n",
      "flag          United States of America \n",
      "flag_type                       Foreign\n",
      "num_loas                            1.0\n",
      "loa                               294.0\n",
      "max_loa                           294.0\n",
      "num_types                           1.0\n",
      "type                              Cargo\n",
      "name                Emerald Princess Ii\n",
      "transit                               1\n",
      "segment                               1\n",
      "seg_length                         19.9\n",
      "avg_sog                             9.7\n",
      "min_sog                             0.0\n",
      "max_sog                            10.0\n",
      "pdgt10                              0.0\n",
      "st_time                   7/19/09 16:55\n",
      "end_time                   4/19/09 8:06\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Mode of the all columns\")\n",
    "print(AIS_merge_data.mode().iloc[0])\n",
    "AIS_merge_data = AIS_merge_data.fillna(AIS_merge_data.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "18453e17-3f63-4c47-862f-e799fad01e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mmsi          0\n",
       "num_names     0\n",
       "names         0\n",
       "sov           0\n",
       "flag          0\n",
       "flag_type     0\n",
       "num_loas      0\n",
       "loa           0\n",
       "max_loa       0\n",
       "num_types     0\n",
       "type          0\n",
       "name          0\n",
       "transit       0\n",
       "segment       0\n",
       "seg_length    0\n",
       "avg_sog       0\n",
       "min_sog       0\n",
       "max_sog       0\n",
       "pdgt10        0\n",
       "st_time       0\n",
       "end_time      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIS_merge_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa4a91-9ae8-44a5-a732-7ba6d56dd011",
   "metadata": {},
   "source": [
    "## Q1) 7. Use z-scores to detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "02fda956-8c3f-4898-92c0-95c425a33232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmsi            int64\n",
      "num_names     float64\n",
      "names          object\n",
      "sov            object\n",
      "flag           object\n",
      "flag_type      object\n",
      "num_loas      float64\n",
      "loa            object\n",
      "max_loa       float64\n",
      "num_types     float64\n",
      "type           object\n",
      "name           object\n",
      "transit         int64\n",
      "segment         int64\n",
      "seg_length    float64\n",
      "avg_sog       float64\n",
      "min_sog       float64\n",
      "max_sog       float64\n",
      "pdgt10        float64\n",
      "st_time        object\n",
      "end_time       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(AIS_merge_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "35124bec-cfd3-4baf-95d7-d8fac142fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_mmsi\"] = (AIS_merge_data[\"mmsi\"] - AIS_merge_data[\"mmsi\"].mean()) /AIS_merge_data[\"mmsi\"].std()\n",
    "outliers_mmsi = AIS_merge_data[AIS_merge_data[\"z_mmsi\"]>3]\n",
    "print(len(outliers_mmsi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a818b0be-353e-4f0b-b8d1-6ec0b2d93bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_num_names\"] = (AIS_merge_data[\"num_names\"] - AIS_merge_data[\"num_names\"].mean()) /AIS_merge_data[\"num_names\"].std()\n",
    "outliers_num_names = AIS_merge_data[AIS_merge_data[\"z_num_names\"]>3]\n",
    "print(len(outliers_num_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a4b54dca-3791-47e3-95b5-8a3a3d8d9ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9970\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_num_loas\"] = (AIS_merge_data[\"num_loas\"] - AIS_merge_data[\"num_loas\"].mean()) /AIS_merge_data[\"num_loas\"].std()\n",
    "outliers_num_loas = AIS_merge_data[AIS_merge_data[\"z_num_loas\"]>3]\n",
    "print(len(outliers_num_loas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fd99238f-08bc-470f-908d-29715b2fd764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_max_loa\"] = (AIS_merge_data[\"max_loa\"] - AIS_merge_data[\"max_loa\"].mean()) /AIS_merge_data[\"max_loa\"].std()\n",
    "outliers_max_loa = AIS_merge_data[AIS_merge_data[\"z_max_loa\"]>3]\n",
    "print(len(outliers_max_loa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "853dc93a-28e4-410f-bd3a-416797d40b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_num_types\"] = (AIS_merge_data[\"num_types\"] - AIS_merge_data[\"num_types\"].mean()) /AIS_merge_data[\"num_types\"].std()\n",
    "outliers_num_types = AIS_merge_data[AIS_merge_data[\"z_num_types\"]>3]\n",
    "print(len(outliers_num_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e3a32f7f-721f-4fea-90a5-65de59ff020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4790\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_transit\"] = (AIS_merge_data[\"transit\"] - AIS_merge_data[\"transit\"].mean()) / AIS_merge_data[\"transit\"].std()\n",
    "outliers_transit = AIS_merge_data[np.abs(AIS_merge_data[\"z_transit\"]) > 3]\n",
    "print(len(outliers_transit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7797c64f-5fd4-4e9d-8851-72f918f5e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_segment\"] = (AIS_merge_data[\"segment\"] - AIS_merge_data[\"segment\"].mean()) / AIS_merge_data[\"segment\"].std()\n",
    "outliers_segment = AIS_merge_data[np.abs(AIS_merge_data[\"z_segment\"]) > 3]\n",
    "print(len(outliers_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9e208c4b-c577-478a-87dd-e210d2321962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_seg_length\"] = (AIS_merge_data[\"seg_length\"] - AIS_merge_data[\"seg_length\"].mean()) / AIS_merge_data[\"seg_length\"].std()\n",
    "outliers_seg_length = AIS_merge_data[np.abs(AIS_merge_data[\"z_seg_length\"]) > 3]\n",
    "print(len(outliers_seg_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4bf39e36-41dc-409c-b9d7-e4ecf69ec313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_avg_sog\"] = (AIS_merge_data[\"avg_sog\"] - AIS_merge_data[\"avg_sog\"].mean()) / AIS_merge_data[\"avg_sog\"].std()\n",
    "outliers_avg_sog = AIS_merge_data[np.abs(AIS_merge_data[\"z_avg_sog\"]) > 3]\n",
    "print(len(outliers_avg_sog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fabfc9de-46c2-47a7-97e4-ac89d4af99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2254\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_min_sog\"] = (AIS_merge_data[\"min_sog\"] - AIS_merge_data[\"min_sog\"].mean()) / AIS_merge_data[\"min_sog\"].std()\n",
    "outliers_min_sog = AIS_merge_data[np.abs(AIS_merge_data[\"z_min_sog\"]) > 3]\n",
    "print(len(outliers_min_sog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8625b63f-c1ef-4b33-8506-3bf7f6ed42d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_max_sog\"] = (AIS_merge_data[\"max_sog\"] - AIS_merge_data[\"max_sog\"].mean()) / AIS_merge_data[\"max_sog\"].std()\n",
    "outliers_max_sog = AIS_merge_data[np.abs(AIS_merge_data[\"z_max_sog\"]) > 3]\n",
    "print(len(outliers_max_sog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e0868229-4681-46a7-9805-83f079604dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "AIS_merge_data[\"z_pdgt10\"] = (AIS_merge_data[\"pdgt10\"] - AIS_merge_data[\"pdgt10\"].mean()) / AIS_merge_data[\"pdgt10\"].std()\n",
    "outliers_pdgt10 = AIS_merge_data[np.abs(AIS_merge_data[\"z_pdgt10\"]) > 3]\n",
    "print(len(outliers_pdgt10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "137e01cc-7d6a-43d7-aa04-cf9f3c4e4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262526\n"
     ]
    }
   ],
   "source": [
    "print(AIS_merge_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "41dd8c0a-2dd6-40a3-ab42-45b539fa1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers :  26949\n"
     ]
    }
   ],
   "source": [
    "print(\"Total outliers : \",len(outliers_mmsi)+len(outliers_num_names)+len(outliers_num_loas)+len(outliers_max_loa)+len(outliers_num_types)+len(outliers_transit)+len(outliers_segment)+len(outliers_seg_length)+len(outliers_avg_sog)+len(outliers_min_sog)+len(outliers_max_sog)+len(outliers_pdgt10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa48e0-d366-42c6-a8e7-c31083de2da3",
   "metadata": {},
   "source": [
    "#### Analysis : The number of outliers are very huge, hence removing the outliers is not feasible. We can implement log normalization or minmax normalization to reduce the number of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10045760-d4e2-446d-908c-0674ad623247",
   "metadata": {},
   "source": [
    "## Q2) 1. create array X of shape (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fea32c8d-6b63-4fb3-af4c-9dfd7b4798e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3 7]\n",
      " [4 6 9]\n",
      " [2 6 7]\n",
      " [4 3 7]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.randint(0, 10, size=(4, 3))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6410b96e-4894-4f91-adf0-f3436a6d59fe",
   "metadata": {},
   "source": [
    "## Q2) 2.write a function dist() to measure the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "160b049d-0c5c-4f0e-ac8c-351fee2f2b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 1 to Point 1: 0.000 (distance to itself)\n",
      "Point 1 [6 3 7] to Point 2 [4 6 9] : 4.123\n",
      "Point 1 [6 3 7] to Point 3 [2 6 7] : 5.000\n",
      "Point 1 [6 3 7] to Point 4 [4 3 7] : 2.000\n",
      "Point 2 [4 6 9] to Point 1 [6 3 7] : 4.123\n",
      "Point 2 to Point 2: 0.000 (distance to itself)\n",
      "Point 2 [4 6 9] to Point 3 [2 6 7] : 2.828\n",
      "Point 2 [4 6 9] to Point 4 [4 3 7] : 3.606\n",
      "Point 3 [2 6 7] to Point 1 [6 3 7] : 5.000\n",
      "Point 3 [2 6 7] to Point 2 [4 6 9] : 2.828\n",
      "Point 3 to Point 3: 0.000 (distance to itself)\n",
      "Point 3 [2 6 7] to Point 4 [4 3 7] : 3.606\n",
      "Point 4 [4 3 7] to Point 1 [6 3 7] : 2.000\n",
      "Point 4 [4 3 7] to Point 2 [4 6 9] : 3.606\n",
      "Point 4 [4 3 7] to Point 3 [2 6 7] : 3.606\n",
      "Point 4 to Point 4: 0.000 (distance to itself)\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        point_i = X[i]\n",
    "        point_j = X[j]\n",
    "        if i == j:\n",
    "            print(f\"Point {i+1} to Point {j+1}: 0.000 (distance to itself)\")\n",
    "        else:\n",
    "            diff = point_i - point_j\n",
    "            squared_diffs = diff ** 2\n",
    "            distance = np.sqrt(np.sum(squared_diffs))\n",
    "            print(f\"Point {i+1} {point_i} to Point {j+1} {point_j} : {distance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364bcb3-09be-4ef8-aa5a-5ba7739adec9",
   "metadata": {},
   "source": [
    "## Q2) 3. Consider adding a new point and add it to X using broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bff11-ffe4-4312-9ebb-0946af4c6e0a",
   "metadata": {},
   "source": [
    "#### Case 1 : A datapoint with coordinate ( 3, 1, 2). This point can be added because, the matrix X and the new data point has same dimension. Hence, can be broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b1f42c68-ee3f-4b43-9929-416cf8ff8766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data point :  (3,)\n",
      "Dimension of the matrix X :  3\n"
     ]
    }
   ],
   "source": [
    "point1 = np.array([3, 1, 2])\n",
    "print(\"Dimension of the data point : \", point1.shape)\n",
    "print(\"Dimension of the matrix X : \", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b1a22d7d-ef90-4c8d-9721-5df5be36be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3 7]\n",
      " [4 6 9]\n",
      " [2 6 7]\n",
      " [4 3 7]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f8cfac22-46fb-4041-81d6-c56b67d1c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  4  9]\n",
      " [ 7  7 11]\n",
      " [ 5  7  9]\n",
      " [ 7  4  9]]\n"
     ]
    }
   ],
   "source": [
    "result1 = X+point1\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2217a8-fadb-4bfc-a83d-706c5606befd",
   "metadata": {},
   "source": [
    "#### Case 2 : A datapoint with coordinate (9, 6). This point cannot be added because, the matrix X and the new data point has different dimension. Hence, cannot be broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "90d4f7c2-3663-4370-ae13-72824a959e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data point :  (2,)\n",
      "Dimension of the matrix X :  3\n"
     ]
    }
   ],
   "source": [
    "point2 = np.array([9,6])\n",
    "print(\"Dimension of the data point : \", point2.shape)\n",
    "print(\"Dimension of the matrix X : \", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6a680a10-5a37-4236-aff1-be24ac9a2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3 7]\n",
      " [4 6 9]\n",
      " [2 6 7]\n",
      " [4 3 7]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2e811e0a-1576-4a52-8f19-1f81f37dfb13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result2 \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mpoint2\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result2)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (2,) "
     ]
    }
   ],
   "source": [
    "result2 = X+point2\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81296f40-6ce1-4e91-ae58-3ea11a15ea5a",
   "metadata": {},
   "source": [
    "#### Case 3 : A datapoint with coordinate (2). This point can be added because, even if the matrix X and the new data point has different dimension,the new point is considered as scalar value and will be added to every element in the matrix. Hence, can be broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5f1e999d-0cc3-4497-931b-3466c96c43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data point :  (1,)\n",
      "Dimension of the matrix X :  3\n"
     ]
    }
   ],
   "source": [
    "point3 = np.array([2])\n",
    "print(\"Dimension of the data point : \", point3.shape)\n",
    "print(\"Dimension of the matrix X : \", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "67972af2-0e14-4942-acea-a3b6573ea499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3 7]\n",
      " [4 6 9]\n",
      " [2 6 7]\n",
      " [4 3 7]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1dbd075b-8d04-494b-af8f-67c6a5c265ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  5  9]\n",
      " [ 6  8 11]\n",
      " [ 4  8  9]\n",
      " [ 6  5  9]]\n"
     ]
    }
   ],
   "source": [
    "result3 = X+point3\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8550ea6-c0c8-4627-8c09-5ff75ab6665f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
